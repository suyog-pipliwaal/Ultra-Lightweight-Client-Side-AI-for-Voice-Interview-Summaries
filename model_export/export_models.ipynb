{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWJ7uqWFm0c3rIxKvWVa+O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install torch transformers onnx onnxruntime onnxruntime-tools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"833iVmIt6GTc","executionInfo":{"status":"ok","timestamp":1766823866535,"user_tz":-330,"elapsed":16093,"user":{"displayName":"Suyog Pipliwal","userId":"03568592090579572693"}},"outputId":"ccb88823-0565-4cee-ff22-e6d4baee868f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n","Collecting onnx\n","  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n","Collecting onnxruntime-tools\n","  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from onnxruntime-tools) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from onnxruntime-tools) (9.0.0)\n","Collecting py3nvml (from onnxruntime-tools)\n","  Downloading py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Collecting xmltodict (from py3nvml->onnxruntime-tools)\n","  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n","Installing collected packages: xmltodict, humanfriendly, py3nvml, onnx, coloredlogs, onnxruntime-tools, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.20.0 onnxruntime-1.23.2 onnxruntime-tools-1.7.0 py3nvml-0.2.7 xmltodict-1.0.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4sEXLmM6L54","executionInfo":{"status":"ok","timestamp":1766823910110,"user_tz":-330,"elapsed":24204,"user":{"displayName":"Suyog Pipliwal","userId":"03568592090579572693"}},"outputId":"c0d3da69-e8de-4617-dc6e-0ac8f84d6115"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ijqz1Iz150W3","executionInfo":{"status":"ok","timestamp":1766823995115,"user_tz":-330,"elapsed":140,"user":{"displayName":"Suyog Pipliwal","userId":"03568592090579572693"}}},"outputs":[],"source":["import os\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","from onnxruntime.quantization import quantize_dynamic, QuantType\n","\n","MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n","ONNX_DIR = \"/content/drive/MyDrive/Colab Notebooks/model_export/onnx\"\n","FP32_MODEL = os.path.join(ONNX_DIR, \"model.onnx\")\n","INT8_MODEL = os.path.join(ONNX_DIR, \"model-int8.onnx\")\n","\n"]},{"cell_type":"code","source":["!pip install -U onnx onnxscript"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cmPtDyj63Bn","executionInfo":{"status":"ok","timestamp":1766824061105,"user_tz":-330,"elapsed":8926,"user":{"displayName":"Suyog Pipliwal","userId":"03568592090579572693"}},"outputId":"141462bc-369c-4ec9-9106-a0563509d345"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.20.0)\n","Collecting onnxscript\n","  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n","Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n","Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n","  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n","Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n","Successfully installed onnx_ir-0.1.13 onnxscript-0.5.7\n"]}]},{"cell_type":"code","source":["os.makedirs(ONNX_DIR, exist_ok=True)\n","\n","print(\"Loading pretrained MiniLM...\")\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model.eval()\n","\n","# Dummy input for export\n","dummy_text = \"This is a test sentence for ONNX export.\"\n","inputs = tokenizer(dummy_text, return_tensors=\"pt\")\n","\n","print(\"Exporting FP32 ONNX model...\")\n","torch.onnx.export(\n","    model,\n","    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n","    FP32_MODEL,\n","    input_names=[\"input_ids\", \"attention_mask\"],\n","    output_names=[\"last_hidden_state\"],\n","    dynamic_axes={\n","        \"input_ids\": {0: \"batch\", 1: \"sequence\"},\n","        \"attention_mask\": {0: \"batch\", 1: \"sequence\"},\n","        \"last_hidden_state\": {0: \"batch\", 1: \"sequence\"},\n","    },\n","    opset_version=17,\n",")\n","\n","print(\"FP32 ONNX saved:\", FP32_MODEL)\n","\n","print(\"Quantizing to INT8...\")\n","quantize_dynamic(\n","    model_input=FP32_MODEL,\n","    model_output=INT8_MODEL,\n","    weight_type=QuantType.QInt8,\n",")\n","\n","print(\"INT8 ONNX saved:\", INT8_MODEL)\n","\n","print(\"Done ✅\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiPZ990z55YG","executionInfo":{"status":"ok","timestamp":1766824094613,"user_tz":-330,"elapsed":29061,"user":{"displayName":"Suyog Pipliwal","userId":"03568592090579572693"}},"outputId":"002201d7-8161-4247-f8f0-db6b81a48335"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pretrained MiniLM...\n","Exporting FP32 ONNX model...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1671631514.py:13: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n","  torch.onnx.export(\n","W1227 08:27:46.693000 693 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"]},{"output_type":"stream","name":"stdout","text":["[torch.onnx] Obtain model graph for `BertModel([...]` with `torch.export.export(..., strict=False)`...\n","[torch.onnx] Obtain model graph for `BertModel([...]` with `torch.export.export(..., strict=False)`... ✅\n","[torch.onnx] Run decomposition...\n","[torch.onnx] Run decomposition... ✅\n","[torch.onnx] Translate the graph into ONNX...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"]},{"output_type":"stream","name":"stdout","text":["[torch.onnx] Translate the graph into ONNX... ✅\n","Applied 42 of general pattern rewrite rules.\n","FP32 ONNX saved: /content/drive/MyDrive/Colab Notebooks/model_export/onnx/model.onnx\n","Quantizing to INT8...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"]},{"output_type":"stream","name":"stdout","text":["INT8 ONNX saved: /content/drive/MyDrive/Colab Notebooks/model_export/onnx/model-int8.onnx\n","Done ✅\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZTgiMNG26sCa"},"execution_count":null,"outputs":[]}]}